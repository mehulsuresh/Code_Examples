{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "|Column|Description|\n",
    "|------|-----------|\n",
    "|PERIOD|transaction month|    \n",
    "|cl_id|client id|\n",
    "|MCC|vendor category code|\n",
    "|channel_type |   customer acquisition channel |\n",
    "|currency |currency|  \n",
    "|TRDATETIME |transaction date / time  |\n",
    "|amount| transaction amount |  \n",
    "|trx_category| type of transaction, POS - payment via POS terminal, C2C_OUT - transfer to card (outgoing payment), C2C_IN - transfer to card (incoming payment), DEPOSIT - card replenishment in ATM, WD_ATM_PARTNER - cash withdrawal at ATMs of partners.|  \n",
    "|target_flag| Whether the customer will continue to use the product after the grace period (1/0) (target) | \n",
    "|target_sum| the amount of POS transactions for three future months (target)|  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:40:21.485722Z",
     "start_time": "2018-05-16T13:40:21.480719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:05.213481Z",
     "start_time": "2018-05-16T13:36:03.703151Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"train.csv\")\n",
    "tf1 = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:05.623140Z",
     "start_time": "2018-05-16T13:36:05.597122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>cl_id</th>\n",
       "      <th>MCC</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>TRDATETIME</th>\n",
       "      <th>amount</th>\n",
       "      <th>trx_category</th>\n",
       "      <th>target_flag</th>\n",
       "      <th>target_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>5200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "      <td>21OCT17:00:00:00</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>POS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "      <td>12OCT17:12:24:07</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>5921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "      <td>05DEC17:00:00:00</td>\n",
       "      <td>767.0</td>\n",
       "      <td>POS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>5411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "      <td>21OCT17:00:00:00</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>POS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "      <td>24OCT17:13:14:24</td>\n",
       "      <td>36562.0</td>\n",
       "      <td>C2C_OUT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PERIOD  cl_id   MCC channel_type  currency        TRDATETIME   amount  \\\n",
       "0  01/10/2017      0  5200          NaN       810  21OCT17:00:00:00   5023.0   \n",
       "1  01/10/2017      0  6011          NaN       810  12OCT17:12:24:07  20000.0   \n",
       "2  01/12/2017      0  5921          NaN       810  05DEC17:00:00:00    767.0   \n",
       "3  01/10/2017      0  5411          NaN       810  21OCT17:00:00:00   2031.0   \n",
       "4  01/10/2017      0  6012          NaN       810  24OCT17:13:14:24  36562.0   \n",
       "\n",
       "  trx_category  target_flag  target_sum  \n",
       "0          POS            0         0.0  \n",
       "1      DEPOSIT            0         0.0  \n",
       "2          POS            0         0.0  \n",
       "3          POS            0         0.0  \n",
       "4      C2C_OUT            0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:24.755983Z",
     "start_time": "2018-05-16T13:36:05.963379Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,12))\n",
    "# sns.heatmap(df1.isnull())\n",
    "df1 = df1.fillna(\"undefined\")\n",
    "\n",
    "# # df1.isnull().sum(axis=0)\n",
    "# plt.figure(figsize=(14,12))\n",
    "# sns.heatmap(df1.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:25.418732Z",
     "start_time": "2018-05-16T13:36:25.064978Z"
    }
   },
   "outputs": [],
   "source": [
    "tf1.isnull().sum(axis=0)\n",
    "tf1 = tf1.fillna(\"undefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:26.276484Z",
     "start_time": "2018-05-16T13:36:25.697197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERIOD             19\n",
       "cl_id            5000\n",
       "MCC               344\n",
       "channel_type        6\n",
       "currency           59\n",
       "TRDATETIME      58113\n",
       "amount          85817\n",
       "trx_category       10\n",
       "target_flag         2\n",
       "target_sum       2651\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONE HOT ENCODING\n",
    "# pd.get_dummies(obj_df, columns=[\"body_style\", \"drive_wheels\"], prefix=[\"body\", \"drive\"]).head()\n",
    "df1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:26.788645Z",
     "start_time": "2018-05-16T13:36:26.609719Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for i in df1.groupby(\"cl_id\").count().target_flag:\n",
    "#     if count < i:\n",
    "#         count = i\n",
    "        \n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T12:40:08.156210Z",
     "start_time": "2018-05-16T12:40:08.011761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:04:12.121147Z",
     "start_time": "2018-05-15T21:04:12.109147Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in df1.cl_id:\n",
    "#     print(i)\n",
    "#     pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:43:20.840791Z",
     "start_time": "2018-05-15T18:43:19.755675Z"
    }
   },
   "outputs": [],
   "source": [
    "# # def month_extract(x):\n",
    "#     x = str(x)\n",
    "#     return(int(x.split(\"/\")[1]))\n",
    "\n",
    "# df1.PERIOD = df1.PERIOD.apply(month_extract)\n",
    "# tf1.PERIOD = tf1.PERIOD.apply(month_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:43:20.856031Z",
     "start_time": "2018-05-15T18:43:20.840791Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df1.currency.unique()\n",
    "# df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:43:54.820764Z",
     "start_time": "2018-05-15T18:43:20.859036Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = pd.get_dummies(df1, columns=[\"PERIOD\", \"cl_id\",\"MCC\",\"channel_type\",\"currency\",\"trx_category\"], prefix=[\"month\", \"client\",\"vendor\",\"channel\",\"currency\",\"trx_cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:58:40.092289Z",
     "start_time": "2018-05-15T18:58:36.722140Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df3 = pd.get_dummies(df1, columns=[\"PERIOD\",\"MCC\",\"channel_type\",\"currency\",\"trx_category\"], prefix=[\"month\",\"vendor\",\"channel\",\"currency\",\"trx_cat\"])\n",
    "# df3 = df3.drop( [\"cl_id\",\"TRDATETIME\",\"target_sum\"], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:44:03.961811Z",
     "start_time": "2018-05-15T18:43:54.820764Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2 = df2.drop( [\"TRDATETIME\",\"target_sum\"], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T19:13:33.369085Z",
     "start_time": "2018-05-15T19:13:33.362080Z"
    }
   },
   "outputs": [],
   "source": [
    "# df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T18:56:07.613162Z",
     "start_time": "2018-05-15T18:56:07.607161Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = df2.drop([\"target_flag\"],axis=1)\n",
    "# y = df2.target_flag\n",
    "# y = pd.get_dummies(y, columns=[\"target_flag\"], prefix=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T19:02:30.244732Z",
     "start_time": "2018-05-15T18:58:49.779135Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from sklearn import metrics\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Activation\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# def to_xy(df, target):\n",
    "#     result = []\n",
    "#     for x in df.columns:\n",
    "#         if x != target:\n",
    "#             result.append(x)\n",
    "#     # find out the type of the target column.  Is it really this hard? :(\n",
    "#     target_type = df[target].dtypes\n",
    "#     target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "#     # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "#     if target_type in (np.int64, np.int32):\n",
    "#         # Classification\n",
    "#         dummies = pd.get_dummies(df[target])\n",
    "#         return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "#     else:\n",
    "#         # Regression\n",
    "#         return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# # Create x & y for training\n",
    "\n",
    "# # Create the x-side (feature vectors) of the training\n",
    "\n",
    "# x, y = to_xy(df3,'target_flag')\n",
    "# # Split into train/test\n",
    "# x_train, x_test, y_train, y_test = train_test_split(    \n",
    "#     x, y, test_size=0.25, random_state=42) \n",
    "\n",
    "# # Build network\n",
    "# model = Sequential()\n",
    "# model.add(Dense(5, input_dim=x.shape[1], activation='relu'))\n",
    "# model.add(Dense(2, activation='relu'))\n",
    "# model.add(Dense(y.shape[1],activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "# checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "# print(model.summary())\n",
    "# model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "# model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# # Measure accuracy\n",
    "# pred = model.predict(x_test)\n",
    "# pred = np.argmax(pred,axis=1)\n",
    "# y_compare = np.argmax(y_test,axis=1)\n",
    "# score = metrics.accuracy_score(y_compare, pred)\n",
    "# print(\"Final accuracy: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:30.031719Z",
     "start_time": "2018-05-16T13:36:27.084852Z"
    }
   },
   "outputs": [],
   "source": [
    "temp2 = pd.get_dummies(df1, columns=[\"MCC\",\"channel_type\",\"currency\",\"trx_category\"], prefix=[\"vendor\",\"channel\",\"currency\",\"trx_cat\"])\n",
    "temp2 = temp2.drop( [\"PERIOD\",\"TRDATETIME\",\"target_sum\"], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:36:30.734917Z",
     "start_time": "2018-05-16T13:36:30.727911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cl_id', 'amount', 'target_flag', 'vendor_742', 'vendor_763',\n",
       "       'vendor_780', 'vendor_1520', 'vendor_1711', 'vendor_1731',\n",
       "       'vendor_1750',\n",
       "       ...\n",
       "       'trx_cat_BACK_TRX', 'trx_cat_C2C_IN', 'trx_cat_C2C_OUT',\n",
       "       'trx_cat_CASH_ADV', 'trx_cat_CAT', 'trx_cat_DEPOSIT', 'trx_cat_POS',\n",
       "       'trx_cat_WD_ATM_OTHER', 'trx_cat_WD_ATM_PARTNER', 'trx_cat_WD_ATM_ROS'],\n",
       "      dtype='object', length=422)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-16T13:40:35.567Z"
    }
   },
   "outputs": [],
   "source": [
    "x1=[]\n",
    "y1=[]\n",
    "# First loop iterate over every user\n",
    "for i in temp2.groupby([\"cl_id\"]):\n",
    "    x2 = []\n",
    "    tempdf = pd.DataFrame(i[1])\n",
    "    if tempdf[\"target_flag\"].sum() != 0:\n",
    "        y1.append(np.array([0,1],dtype=np.float32))\n",
    "    else:\n",
    "        y1.append(np.array([1,0],dtype=np.float32))\n",
    "    tempdf = tempdf.drop( [\"cl_id\",\"target_flag\"], axis=1 )\n",
    "    #Second loop iterate over every transaction\n",
    "    for index, row in tempdf.iterrows():\n",
    "        x3 = []\n",
    "        #third loop iterate over every feature\n",
    "        for i in row:\n",
    "            x3.append(i)\n",
    "        x2.append(np.array(x3,dtype=np.float32))\n",
    "    if len(x2) < 784:\n",
    "        for j in range(784-len(x2)):\n",
    "            x2.append(np.zeros(420))\n",
    "    x1.append(np.array(x2))\n",
    "x1 = np.array(x1)\n",
    "y1 = np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5023.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [20000.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  767.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]],\n",
       "\n",
       "       [[  380.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  378.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  199.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]],\n",
       "\n",
       "       [[ 3719.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [10000.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [ 1399.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 7050.39990234,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  139.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [ 9235.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]],\n",
       "\n",
       "       [[  320.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  244.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [21110.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]],\n",
       "\n",
       "       [[ 5000.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [10000.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [  274.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        ...,\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ],\n",
       "        [    0.        ,     0.        ,     0.        , ...,\n",
       "             0.        ,     0.        ,     0.        ]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-16T13:40:36.145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784, 420) (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape,y1.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x1, y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-16T13:40:36.722Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-16T13:40:39.370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 3350 samples, validate on 1650 samples\n",
      "Epoch 1/200\n",
      "3350/3350 [==============================] - 25s 7ms/step - loss: 1.6532 - val_loss: 0.6926\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69264, saving model to best_weights.hdf5\n",
      "Epoch 2/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6926 - val_loss: 0.6918\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69264 to 0.69181, saving model to best_weights.hdf5\n",
      "Epoch 3/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6922 - val_loss: 0.6910\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69181 to 0.69099, saving model to best_weights.hdf5\n",
      "Epoch 4/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6916 - val_loss: 0.6903\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69099 to 0.69030, saving model to best_weights.hdf5\n",
      "Epoch 5/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6913 - val_loss: 0.6896\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69030 to 0.68961, saving model to best_weights.hdf5\n",
      "Epoch 6/200\n",
      "3350/3350 [==============================] - 24s 7ms/step - loss: 0.6909 - val_loss: 0.6890\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68961 to 0.68905, saving model to best_weights.hdf5\n",
      "Epoch 7/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6907 - val_loss: 0.6885\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68905 to 0.68850, saving model to best_weights.hdf5\n",
      "Epoch 8/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6904 - val_loss: 0.6880\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68850 to 0.68804, saving model to best_weights.hdf5\n",
      "Epoch 9/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6902 - val_loss: 0.6876\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68804 to 0.68765, saving model to best_weights.hdf5\n",
      "Epoch 10/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6900 - val_loss: 0.6872\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.68765 to 0.68722, saving model to best_weights.hdf5\n",
      "Epoch 11/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6898 - val_loss: 0.6869\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.68722 to 0.68689, saving model to best_weights.hdf5\n",
      "Epoch 12/200\n",
      "3350/3350 [==============================] - 24s 7ms/step - loss: 0.6897 - val_loss: 0.6866\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68689 to 0.68658, saving model to best_weights.hdf5\n",
      "Epoch 13/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6896 - val_loss: 0.6863\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68658 to 0.68633, saving model to best_weights.hdf5\n",
      "Epoch 14/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6895 - val_loss: 0.6861\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68633 to 0.68615, saving model to best_weights.hdf5\n",
      "Epoch 15/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6895 - val_loss: 0.6859\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.68615 to 0.68594, saving model to best_weights.hdf5\n",
      "Epoch 16/200\n",
      "3350/3350 [==============================] - 23s 7ms/step - loss: 0.6894 - val_loss: 0.6858\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.68594 to 0.68577, saving model to best_weights.hdf5\n",
      "Epoch 17/200\n",
      "3350/3350 [==============================] - 24s 7ms/step - loss: 0.6893 - val_loss: 0.6856\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.68577 to 0.68562, saving model to best_weights.hdf5\n",
      "Epoch 18/200\n",
      "3350/3350 [==============================] - 24s 7ms/step - loss: 0.6893 - val_loss: 0.6855\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.68562 to 0.68549, saving model to best_weights.hdf5\n",
      "Epoch 19/200\n",
      "3350/3350 [==============================] - 24s 7ms/step - loss: 0.6893 - val_loss: 0.6854\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.68549 to 0.68539, saving model to best_weights.hdf5\n",
      "Epoch 00019: early stopping\n",
      "Final accuracy: 0.5709090909090909\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout=0.2, input_shape=(None, 420),activation='relu'))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dense(200,activation = 'relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True) # save best model\n",
    "print('Train...')\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],callbacks=[monitor,checkpointer],verbose=1,epochs=200,batch_size=512)\n",
    "model.load_weights('best_weights.hdf5')\n",
    "pred = model.predict(X_test)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_compare, predict_classes)\n",
    "print(\"Final accuracy: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T13:37:33.579854Z",
     "start_time": "2018-05-16T13:37:30.359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.5709090909090909\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('best_weights.hdf5')\n",
    "pred = model.predict(X_test)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_compare, predict_classes)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46310514, 0.53689486],\n",
       "       [0.46310514, 0.53689486],\n",
       "       [0.46310514, 0.53689486],\n",
       "       ...,\n",
       "       [0.46310514, 0.53689486],\n",
       "       [0.46310514, 0.53689486],\n",
       "       [0.46310514, 0.53689486]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
